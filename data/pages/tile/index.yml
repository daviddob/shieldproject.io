---
# vim:ft=markdown:tw=76
title: SHIELD Pivotal Tile
url:   /tile/index.html
format: markdown
--- |-
Welcome to the documentation for the SHILED Enterprise Data Protection Tile beta.

# What is SHIELD?

SHIELD is a _data protection_ solution. It is designed to run scheduled
tasks to backup your important data systems to off-site cloud storage
solutions, and facilitate the restoration of backup archives in the event of
outages or data loss.

# Where Can I Get SHIELD?

SHIELD will ultimately be available on Pivnet but for this beta phase you can
find it [here](#).

# How do I install SHIELD?
1. Once you have the tile downloaded, navigate to your Pivotal Operations Manager
   and click `Import Product` and select the tile from your personal machine.

2. Right under `Import Product` find the versioned SHIELD tile and click `+` to
   begin staging the tile

# Configuring the Tile

The first required fields for the install are associated with the identity of SHIELD

## Identity

![identity](/tile/identity.png)

From here we need to specify:

- `Environment Name`. This is the name used to identify the SHILED itself as well
  as target your SHIELD instance with the cli.

- `Domain`. The domain in which you will be using for shield.

- `Web Interface Color`. A color to help better identify this shield. This is often
  useful when dealing with multiple SHIELD across multiple environments.

- `Message of the Day` An optional message of the day that gets displayed on the login page.
  This can be used to further describe and differentiate multiple shields.

## Scheduling

![scheduling](/tile/scheduling.png)

There are three optional properties available for adjusting how SHIELD schedules jobs.

From here we can specify:

- `Scheduler Threads`. Threads determine how many concurrent tasks SHIELD core can perform at once.
  More threads will allow more backup/restore operations at one time, but requires more cpu and ram.

- `Slow Loop Interval`. How often (in seconds) SHIELD performs non critical operations such as cloud storage
  viability tests, archive purgation, storage analysis calculations, etc.

- `Task Execution Timeout`. How long (in hours) a task can run before the SHIELD core considers it stalled
  and cancels its execution.

## Authentication

![authentication](/tile/authentication.png)

We now need to configure our authentication details for SHIELD.

From here we can specify:

- `Session Timeout`. Maximum lifetime (in hours) of an authenticated session, either web or CLI.

- `Failsafe Account Username`. When SHIELD core starts up it checks the local users database, and if it finds
  no users it will create the failsafe account. This allows you to provide secure default credentials.

- `Failsafe Account Password`. The required secret password for the failsafe account, you can change this after
  SHIELD deploys and your changes will persist.

- `Authentication Provider JSON Config`. The raw SHIELD authentication provider configuration, for using GitHub
  and/or PCF UAA to authenticate SHIELD users. Examples for [github](https://github.com/starkandwayne/shield/blob/master/docs/auth/github.md) and [uaa](https://github.com/starkandwayne/shield/blob/master/docs/auth/uaa.md) can be found here.

## Storage

![storage](/tile/storage.png)

We can now set system wide archive retention policies.

From here we can specify:

- `Minimum Retention Period`. The shortest allowed retention period (in days).

- `Maximum Retention Period`. The longest allowed retention period (in days).

## Encryption & Security

![security](/tile/security.png)

- `API TLS`. The x509 certificate used for the SHIELD API signed for your SHIELD domain and 127.0.0.1.

## Resource Config

![resource](/tile/resource.png)

From here you can specify resource specifics for the SHIELD instance itself.

## Deploy SHIELD

Once the SHIELD tile is configured navigate to back to your dashboard and click `Apply Changes`

# Post Deploy

After you deploy SHIELD your next step would be add a dns record for your domain to point at your
new SHIELD instance. Once this is done we can now navigate to the configure domain to visit SHIELD.

## First login

Navigate to your SHIELD and you'll be greeted by your authentication page. Use your failsafe account
to authenticate and you'll have two first time login tasks.

## Upload your Runtime Config

In order to colocate your shield agents on the data systems you wish to backup we need to create a
runtime config. To do this we need to ssh onto your ops manager vm and create a named `runtime-config`

    addons:
    - name: shield-agent
      include:
        deployments: []
        jobs: []
      jobs:
        - name:  shield-agent
          release: shield
          properties:
            shield-url: {your shield domain}
            require-shield-core: false
            core:
              ca: |
              ((/opsmgr/{your shield deployment name}}/api_tls.cert_pem))
            agent:
              key: |
                ((/opsmgr/{your shield deployment name}/shield_agent_key.public_key_openssh))

    releases:
      - name: shield
        version: {current shield release being use}

You will want to login and target your bosh director with the `bosh commandline credentials` taken from Ops Manager.
Your deployment name and shield release version can be found from a `bosh deployments`. To coload a shield agent, you can
specify a given deployment in which every instance under that deployment will be deployed with the shield-agent job.
Alternatively you can specify a job such as `[postgres, mysql]` where every instance that includes that job will include
a shield agent on it's next deploy.

Once your runtime config is created, upload it with a `bosh update-runtime-config {file-name}`.

Once uploaded, run `Apply Changes` for any services that you specified to contain shield-agents
from your runtime-config.

### Initialize SHIELD

SHIELD uses an internal encrypted vault of secrets. Protecting this vault requires a master password.
Create a master password and store it in your prefered password store.

![master-pass](/tile/master-pass.png)

### SHIELD Fixed Key

You will now be presented with the fixed key to be used for the recovery of fixed-key backups in a
disaster scenario. Fixed key backups must be used to backup shield itself. This is the only time you
can see this key so save it to a safe and secure place.

![fixed-key](/tile/fixed-key.png)

# Operators Guide

A quick rundown of shield concepts and operating procedures to help get started.

## SHIELD core

The **SHIELD Core** is the heart, mind, and soul of a SHIELD installation.
It is responsible for scheduling, metadata, configuration, monitoring, and
much more.

The core is composed of several discrete components that all cooperate to
deliver on the promise of data protection.  They include:

  1. The **SHIELD Database**
  2. The **SHIELD Vault**
  3. The **SHIELD Scheduler**
  4. The **SHIELD Workers**
  5. The **SHIELD API**

## SHIELD Agents

Without **SHIELD Agents**, nothing would get done.  These distributed bits
of software are responsible for executing all manner of tasks, from backups,
to restores, to archive purgation and validation testing.

Each agent uses locally installed _plugins_ to interact with _targets_ and
_stores_ to run backups, perform restores, prune archives, etc.

## Plugins

**Plugins** enable SHIELD to communicate with several different target data
systems, and cloud storage solutions.  These standalone
executables operate according to a known protocol,

// FIXME document the SHIELD plugin protocol

and allow operators and system integrators to support data systems and
storage backends we haven't even dreamt up yet.

For a list of the currently implemented plugins that ship with SHIELD
itself, see our [plugin documentation](/docs/plugins).

- **Tenants**: Shield provides tenancy to allow the separation of teams/environments by allowing tenants to be created. Under a tenant users can be assigned 
               and given roles, stores can be created, and individual systems can be backed up.

## Targets

A **target** is a data system, and they vary wildly.  A PostgreSQL database
can be a target.  So can a Consul key-value store, or a Redis installation.
If there's data (or live configuration that you don't want to lose), you can
bet SHIELD thinks of it as a target.

SHIELD Agents interact with targets via _target plugins_.

## Stores

A **store** is a storage system, usually off-site, redundant, remote, or all
three.  SHIELD stores archives in these systems, and then retrieves those
archives for restoration tasks, later.  Prominent, well-known stores include
Amazon S3, WebDAV, Backblaze, etc.

SHIELD Agents interact with stores via _store plugins_.

## What is a Tenant?


A Tenant is a single group that defines the context for interaction with resources in a SHIELD configuration.
All retention policies, jobs, backup targets, storage endpoints and archives belong to a single tenant.

For example, a SHIELD may serve the infrastructure team and two application development teams.
Each of these groups needs to be able to specify their backup job configuration, how long to keep
the archives (retention policies), what to backup (targets and jobs), and where to store the archives (storage).

Tenancy exists to keep these three groups isolated from one another, for the following purposes:

- To insulate change
- To protect confidentiality of systems

By insulating change we mean that one team is free to reconfigure how long they retain their backups,
without affecting the other teams adversely. The infrastructure team, for example, may need to keep several months
of platform backups, so long-term for them might be 90d. To the app teams, long-term might be a week.

Therefore, each tenant gets its own set of retention policies, and they can determine what "long-term" means to them.

Confidentiality is protected on two fronts. First, and foremost, the archives created as a result of performing backups
must only be available to that tenant. If the infrastructure team regularly backs up a centralized account store
(which contains personnel data), the application teams should be prohibited from restoring those archives to a system they control.
Otherwise, personal information will be at risk.

Therefore, each archive is assigned to the tenant who owns the job that created it, and tenants are prevented from accessing
or viewing another tenant's backups.

The other aspect of confidentiality relates to target and storage configuration. These endpoint configurations contain sensitive material,
like S3 access keys, database credentials, and API tokens. Viewing these outside the scope of the tenant who owns them is a
serious breach of the trust model.

Therefore, each tenant creates and manages its own target and storage configurations, and tenants are prevented from accessing
or viewing another tenant's configuration.

The upshot of all of this is that each tenant operates inside the SHIELD instance as if they were the only tenant present;
they cannot see or interact with the other tenants.
